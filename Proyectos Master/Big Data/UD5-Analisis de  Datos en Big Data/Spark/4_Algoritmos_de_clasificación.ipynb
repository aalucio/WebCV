{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Algoritmos de clasificación\n",
        "\n",
        "Los algoritmos de **clasificación** son uno de los dos tipos en los que pueden divisirse los algoritmos de **aprendizaje supervisado**. Estos algoritmos suponen que partimos de un conjunto de datos etiquetado previamente.\n",
        "\n",
        "Un algoritmo de clasificación se centra en resolver problemas en los cuales se debe predecir el valor de la variable cualitativa $\\mathbf y$ a partir de la variable $\\mathbf x$. En clasificación la variable $\\mathbf{x}$ se denomina **características** o **atributos** mientras que $\\bf y$ se denomina **etiqueta**."
      ],
      "metadata": {
        "id": "hV9Tl5mDW3ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Solicitar acceso y montar en el sistema tu directorio de Google Drive\n",
        "# Esto permitirá la persistencia de datos entre distintas sesiones\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Creamos un directorio para este notebook y lo asociamos\n",
        "drive_path = '/content/drive/MyDrive/Colab Notebooks/ia-bd-m4-sistemas-de-big-data'\n",
        "nb_path = '/content/ia-bd-m4-sistemas-de-big-data'\n",
        "\n",
        "if not os.path.exists(drive_path):\n",
        "    os.makedirs(drive_path)\n",
        "os.symlink(drive_path, nb_path)\n",
        "sys.path.insert(0,nb_path)\n",
        "\n",
        "%cd $nb_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YfyHadXW7Nh",
        "outputId": "fdbf223e-e4c2-41ed-ae04-ea74739fb648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/ia-bd-m4-sistemas-de-big-data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalación de spark en Google Colab"
      ],
      "metadata": {
        "id": "SY1SM1IfXMWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark está escrito en el lenguaje de programación Scala, por lo que requiere\n",
        "# de una máquina virtual de Java (JVM) para funcionar. Por lo tanto, lo primero\n",
        "# es instalar java:\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "CLZdFjR1XOT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Instalación de Apache Spark en Google Colab (Ejecutar solo si no se ha realizado nunca)\n",
        "# Nota: Puede tardar unos minutos (se paciente)\n",
        "# El siguiente paso es elegir una versión reciente de spark\n",
        "# En este notebook, se usará spark versión 3.1.2, la cual puede descargarse en:\n",
        "spark_file = 'spark-3.1.2-bin-hadoop3.2.tgz'\n",
        "spark_url = 'https://archive.apache.org/dist/spark/spark-3.1.2/' + spark_file\n",
        "\n",
        "# A continuación, descargamos la versión elegida de spark:\n",
        "import os # Libreria de manejo del sistema operativo\n",
        "os.system(\"wget -q {spark_url} -P \" + nb_path) # Realizamos la descarga\n",
        "os.system(\"tar xf \" + nb_path + \"/\" + spark_file) # Descomprimimos el fichero .tgz\n",
        "\n",
        "# Realizamos la instalación de pyspark utilizando la herramienta pip\n",
        "!pip install --target=$nb_path -q pyspark\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuJlXcqvXR6d",
        "outputId": "d2fad99f-943f-4383-d028-58c143e9f77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Target directory /content/ia-bd-m4-sistemas-de-big-data/py4j-0.10.9.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/ia-bd-m4-sistemas-de-big-data/pyspark already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/ia-bd-m4-sistemas-de-big-data/py4j already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/ia-bd-m4-sistemas-de-big-data/pyspark-3.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/ia-bd-m4-sistemas-de-big-data/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Target directory /content/ia-bd-m4-sistemas-de-big-data/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Damos permisos de ejecución\n",
        "!chmod -R +x ./pyspark/\n",
        "\n",
        "# Finalmente, es necesario definir algunas variables de entorno en el sistema\n",
        "# operativo para poder usar spark correctamente:\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = nb_path + \"/pyspark\""
      ],
      "metadata": {
        "id": "7P8qYAiXXjhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar el conjunto de datos que se utilizará\n",
        "\n",
        "En este caso utilizaremos un conjunto de datos completo sobre la autentificación de billetes (*banknote_authentication.csv*). Este dataset ha sido obtenido del repositorio [UCI](https://archive.ics.uci.edu/ml/datasets/banknote+authentication).\n",
        "\n",
        "Los datos se extrajeron de imágenes tomadas de ejemplares de billetes auténticos y falsificados. Para la digitalización se utilizó una cámara industrial utilizada habitualmente para la inspección de impresos. Las imágenes finales tienen 400x 400 píxeles. Debido a la lente del objeto y a la distancia al objeto investigado se obtuvieron imágenes en escala de grises con una resolución de unos 660 ppp. Se utilizó la herramienta de transformación Wavelet para extraer las características de las imágenes.\n",
        "\n",
        "Hay 1372 observaciones (imágenes de billetes de banco). Hay 4 variables de predicción (varianza de la imagen, asimetría, curtosis, entropía). La variable a predecir se codifica como 0 (billete auténtico) o 1 (billete falso)."
      ],
      "metadata": {
        "id": "gLhJrkfsXkZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar el dataset que se utilizará utilizando un enlace compartido de google drive\n",
        "# El fichero puede descargarse directamente de la fuente proporcionada, o se\n",
        "# puede utilizar el siguiente código para descargarlo de google drive:\n",
        "# URL: https://drive.google.com/file/d/1CvOH2oT8iptb6vL2eJPmZuukE6O_J1Me\n",
        "!gdown --id 1CvOH2oT8iptb6vL2eJPmZuukE6O_J1Me"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-2b--smXzfJ",
        "outputId": "5631356f-c8fb-42a0-d6d9-0c18a7a1339a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CvOH2oT8iptb6vL2eJPmZuukE6O_J1Me\n",
            "To: /content/drive/MyDrive/Colab Notebooks/ia-bd-m4-sistemas-de-big-data/banknote_authentication.csv\n",
            "100% 46.4k/46.4k [00:00<00:00, 98.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un cluster de Spark e importamos el dataframe actual en Spark."
      ],
      "metadata": {
        "id": "BXJPlHLjX3gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar pyspark.sql\n",
        "from pyspark.sql import*\n",
        "\n",
        "# Importar SparkContext and SparkConf\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# Establecer las propiedades de Spark:\n",
        "# - URL de conexión\n",
        "# - Nombre de la aplicación\n",
        "conf = SparkConf().setMaster(\"local\").setAppName(\"4-Algoritmos-de-clasificacion\")\n",
        "\n",
        "# Iniciar un cluster de Spark (puede tardar unos minutos)\n",
        "# Comprobar si ya existe este cluster y en el caso contrario crear uno nuevo\n",
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "\n",
        "# Mostramos el cluster creado\n",
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "ATc3_ZRNX5ZT",
        "outputId": "d282a62f-9d94-41c7-974b-1386a755affd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local appName=4-Algoritmos-de-clasificacion>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b81b0d388f3e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>4-Algoritmos-de-clasificacion</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar SQLContext a partir del cluster Spark creado anteriormente\n",
        "sqlContext = SQLContext(sc)\n",
        "\n",
        "# Creamos un dataframe a partir del archivo CSV descargado anteriormente y\n",
        "# que contiene el dataset que utilizaremos en esta sesión\n",
        "df = sqlContext.read.csv('banknote_authentication.csv', header=True, sep=\",\", inferSchema = \"true\")\n",
        "\n",
        "# Mostrar el contenido del dataframe (las 5 primeras observaciones). Forgery = 0 --> billete verdadero\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE519hQ-YC0J",
        "outputId": "1b70cbe7-da06-4e35-9b9e-71cd6ff98e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ia-bd-m4-sistemas-de-big-data/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+--------+--------+-------+\n",
            "|variance|skewness|curtosis| entropy|forgery|\n",
            "+--------+--------+--------+--------+-------+\n",
            "|  3.6216|  8.6661| -2.8073|-0.44699|      0|\n",
            "|  4.5459|  8.1674| -2.4586| -1.4621|      0|\n",
            "|   3.866| -2.6383|  1.9242| 0.10645|      0|\n",
            "|  3.4566|  9.5228| -4.0112| -3.5944|      0|\n",
            "| 0.32924| -4.4552|  4.5718| -0.9888|      0|\n",
            "+--------+--------+--------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-procesamiento del dataset y obtención de conjuntos de entrenamiento y test\n",
        "\n",
        "Utilizaremos el *VectorAssembler* para generar una nueva columna en el dataframe la cual tendrá un vector del tipo DenseVector conteniendo todas las características del dataset. Recordad que este era un paso necesario antes de aplicar cualquier algoritmo de ML de la biblioteca [MLlib de Spark](https://spark.apache.org/docs/latest/ml-guide.html)."
      ],
      "metadata": {
        "id": "nJQClALwYT6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "  inputCols = ['variance', 'skewness', 'curtosis', 'entropy'],\n",
        "  outputCol = \"features\"\n",
        ")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Mostramos la nueva columa \"features\" para las 5 primeras filas del dataset\n",
        "df.select(\"features\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXIdujsEYZyp",
        "outputId": "53a40fa1-f4e7-44ed-c39f-ad957bec12e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------+\n",
            "|features                        |\n",
            "+--------------------------------+\n",
            "|[3.6216,8.6661,-2.8073,-0.44699]|\n",
            "|[4.5459,8.1674,-2.4586,-1.4621] |\n",
            "|[3.866,-2.6383,1.9242,0.10645]  |\n",
            "|[3.4566,9.5228,-4.0112,-3.5944] |\n",
            "|[0.32924,-4.4552,4.5718,-0.9888]|\n",
            "+--------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Posteriormente procedemos a estandarizar las entradas numéricas con las que contamos. Este es un proceso muy recomendable para la aplicación de algunos de los algoritmos de clasificación, como por ejemplo para la regresión logística. El escalado que aplicaremos será una [estandarízación](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StandardScaler.html) de desviación estándar la unidad.\n",
        "\n",
        "Recomendamos al lector consultar otro tipo de escalados utilizados con bastante frecuencia. Por ejemplo: [RobustScaler](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.RobustScaler.html), [MinMaxScaler](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.MinMaxScaler.html) y [MaxAbsScaler](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.MaxAbsScaler.html).\n",
        "\n",
        "No podemos olvidar que si llegaran nuevos datos para hacer predicciones deberemos aplicar tanto el transform anterior como el escalado siguiente."
      ],
      "metadata": {
        "id": "cJdpo5fHYi1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicamos el standard Scaler\n",
        "from pyspark.ml.feature import StandardScaler\n",
        "\n",
        "scaler = StandardScaler(inputCol='features',outputCol='standardized')\n",
        "fit_scaler = scaler.fit(df)\n",
        "df = fit_scaler.transform(df)\n",
        "\n",
        "# Mostramos la nueva columa \"standardized\" para las 5 primeras filas del dataset\n",
        "df.select(\"standardized\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUHcGqJ-YmjE",
        "outputId": "457f164f-da63-4d90-b4fc-35c9f5497bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------+\n",
            "|standardized                                                                     |\n",
            "+---------------------------------------------------------------------------------+\n",
            "|[1.273972021962275,1.47657709649511,-0.6513411603422402,-0.21274974061406512]    |\n",
            "|[1.599113489794098,1.391605887067327,-0.5704368527828988,-0.6959023596765579]    |\n",
            "|[1.3599447307560621,-0.44952785609248086,0.4464469991559643,0.05066603254741098] |\n",
            "|[1.2159298904116411,1.622546286623006,-0.9306663564153435,-1.7107936814317894]   |\n",
            "|[0.11581691752564043,-0.7591011274166019,1.0607350539139577,-0.47063008908294945]|\n",
            "+---------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a dividir el dataset en un conjunto de entrenamiento y otro de test. Gracias a esto, podremos estimar cada modelo sobre el conjunto de entrenamiento, utilizando el conjunto de test para validar los resultados obtenidos."
      ],
      "metadata": {
        "id": "AvlIpu4aZj7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividimos entre entrenamiento (70%) y test (30%)\n",
        "(train_df, test_df) = df.randomSplit([0.7, 0.3], seed=100)\n",
        "\n",
        "print(\"Número de filas df entrenamiento: {train:d}\".format(train=train_df.count()))\n",
        "print(\"Número de filas df test: {test:d}\".format(test=test_df.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa03ZWHgZqfp",
        "outputId": "d3b0e059-4293-46e1-9be3-98f322bd0a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de filas df entrenamiento: 968\n",
            "Número de filas df test: 404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión logística\n",
        "\n",
        "Para más información sobre la implementación de PySpark sobre la regresión logistica puede consultar la [documentación de la API](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LogisticRegression.html)."
      ],
      "metadata": {
        "id": "69ojqj3-Z1Ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ajuste de hiperparámetros del modelo.**\n",
        "\n",
        "Tema complejo que se escapa de los contenidos de este curso. Todos los algoritmos tienen una serie de hiperparámetros para ajustar el modelo. Dependiendo del dataset, el algoritmo se comportará mejor o peor con unos valores u otros para esos hiperparámetros. Hay que intentar ajustarlos sin sobreajustar. Una solución es el tuning de parametros.\n",
        "\n",
        "Uno de los enfoques para hacer esto es construir una rejilla en función del número de hiperparámetros que queramos ajustar. Para cada uno definimos unos valores.\n",
        "\n",
        "Mediante el uso del objeto CrossValidator se puede dividir el conjunto de datos en un subconjunto de pliegues (folds) que se utilizan como conjuntos de datos de entrenamiento y de prueba separados. Esta técnica se conoce como cross-validación. Por ejemplo, con k=3 pliegues, CrossValidator generará 3 pares de conjuntos de datos (de entrenamiento, de prueba), cada uno de los cuales utiliza 2/3 de los datos para el entrenamiento y 1/3 para la prueba. Para evaluar cada conjunto de parámetros posibles, CrossValidator calcula la métrica de evaluación media para los 3 modelos producidos al ajustar el estimador en los 3 pares de conjuntos de datos diferentes (entrenamiento, prueba)."
      ],
      "metadata": {
        "id": "4W550ggoZutZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "lr = LogisticRegression(labelCol=\"forgery\", featuresCol=\"standardized\",\n",
        "                        maxIter=100)\n",
        "\n",
        "# Definimos los parámetros del grid donde se buscarán los parámetros óptimos. Con el punto vamos concatenando.\n",
        "# Los valores 1; 0,1; 0,01; etc --> Experiencia, consulta de documentación sobre el algoritmo...\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(lr.regParam, [1, 0.1, 0.01, 0.001]) \\\n",
        "    .build()\n",
        "\n",
        "# Ya tenemos algoritmo y rejilla. Definimos evaluador. En este caso binario (hay más).\n",
        "# Definimos también sus hiperparámetros\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"forgery\", rawPredictionCol=\"prediction\")\n",
        "\n",
        "# Definimos la cross-validación\n",
        "crossval = CrossValidator(estimator=lr,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)\n",
        "\n",
        "# Ejecutar la cross-validación y elegir el mejor conjunto de parámetros\n",
        "# En este caso solo se buscó uno\n",
        "cvModel = crossval.fit(train_df)\n",
        "\n",
        "print(\"RegParam: \" + str(cvModel.bestModel.getRegParam()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e71chLLUZ6Ub",
        "outputId": "0e1b94d3-0970-45a5-b28c-fcdf2590ab22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RegParam: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del modelo.**"
      ],
      "metadata": {
        "id": "XlypFpX8aHfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar un modelo de regresión logistica binario (2 clases)\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Hiperparámetros. Forgery seria laetiqueta, standardized el dense vector escalado. Los otros dos se han ajustado en lacelda anterior.\n",
        "# Según el algoritmo puede que nos vengan dados. En otros casos se calculan como en la celda anterior\n",
        "lr = LogisticRegression(labelCol=\"forgery\", featuresCol=\"standardized\",\n",
        "                        maxIter=100, regParam=0.001)\n",
        "# Modelo ajustado\n",
        "lr_model = lr.fit(train_df)\n",
        "\n",
        "# Aplicamos el modelo sobre el conjunto de test\n",
        "pred = lr_model.transform(test_df)\n",
        "\n",
        "# Mostramos las clases reales junto con las predicciones realizadas\n",
        "pred.select(\"forgery\", \"features\", \"prediction\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwzqqIcyaJGh",
        "outputId": "149bd476-83e8-4617-ac32-6482e56070af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+----------+\n",
            "|forgery|            features|prediction|\n",
            "+-------+--------------------+----------+\n",
            "|      1|[-6.7526,8.8172,-...|       1.0|\n",
            "|      1|[-6.3979,6.4479,1...|       1.0|\n",
            "|      1|[-6.3679,8.0102,0...|       1.0|\n",
            "|      1|[-6.2003,8.6806,0...|       1.0|\n",
            "|      1|[-6.1632,8.7096,-...|       1.0|\n",
            "|      1|[-5.8818,7.6584,0...|       1.0|\n",
            "|      1|[-5.873,9.1752,-0...|       1.0|\n",
            "|      1|[-5.4414,7.2363,0...|       1.0|\n",
            "|      1|[-5.2406,6.6258,-...|       1.0|\n",
            "|      1|[-5.0676,-5.1877,...|       1.0|\n",
            "+-------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar los coeficientes y los términos de interceptación de la regresión logistica\n",
        "# Al final se trata de una recta\n",
        "print(\"Coeficientes (1 por variable): \" + str(lr_model.coefficientMatrix))\n",
        "print(\"Terminos de interceptación: \" + str(lr_model.interceptVector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFyN1OnyclrN",
        "outputId": "73bbe340-1c1d-4fa6-9fe5-8631f29db2e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes (1 por variable): DenseMatrix([[-4.60923365, -4.66366829, -4.24543597,  0.23898744]])\n",
            "\n",
            "Terminos de interceptación: [2.332104765021363]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del modelo.**\n",
        "\n",
        "Vamos a ver cómo se comporta el modelo en los datos de test, utilizando el valor de la exactitud o **accuracy** que mide el porcentaje de casos que el modelo ha acertado (fracción de predicciones correctas): predicciones correctas / número total de elementos.\n",
        "\n",
        "Se debe tener cuidado, pues esta es una métrica muy engañosa. De hecho, si tuviésemos un modelo que siempre predijera siempre una de las clases, el resultado sería el porcentaje de elementos de dicha clase. ¿Qué pasa si el problema está desbalanceado y hay muchas observaciones de dicha clase? Se deben tener en cuenta más indicadores. No obstante, esto queda fuera de los contenidos de este curso y se estudiarán en el módulo de Sistemas de Aprendizaje Automático. Problema con un modelo dummy que sobre un dataset 90-10 siempre evalue cierto.\n",
        "\n",
        "En el módulo SAA se aprenderán diferentes métricas para evaluar los algoritmos.\n",
        "\n",
        "En este caso se va a usar un **MulticlassClassificationEvaluator** que también funciona para clases binarias."
      ],
      "metadata": {
        "id": "08KuL2OKcvLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"forgery\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(pred)\n",
        "print(\"Accuracy: {}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc-dDI0zc1ay",
        "outputId": "4a9e85c8-a610-4280-e35d-156de87824ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9801980198019802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podremos observar también la **matriz de confusión**.\n",
        "La matriz de confusión es una herramienta muy útil para valorar cómo de bueno es un modelo clasificación. En particular, sirve para mostrar de forma explícita cuándo una clase es confundida con otra. Cada columna de la matriz representa el número de predicciones de cada clase, mientras que cada fila representa a las instancias en la clase real.\n",
        "\n",
        "Para ello, lo primero que haremos será crear un nuevo dataframe solo con las prediciones y la clase real (los resultados corectos, es decir, la columna \"forgery\"). Posteriormente, tenemos que hacer un casting a la columna \"forgery\" para pasarla de entero a float, ya que la función para obtener la matriz de confusión solo funcionará con floats. Por último, mapeamos el dataframe en un RDD como una tupla y pasamos esta a la función MulticlassMetrics de MLlib."
      ],
      "metadata": {
        "id": "-mSTH2MEdM5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# Selecionamos solo las prediciones y los valores reales (forgery)\n",
        "preds_and_labels = pred.select(['prediction','forgery'])\n",
        "# Hacemos un casting de entero a float para la columna forgery\n",
        "preds_and_labels = preds_and_labels.withColumn(\"forgery\", preds_and_labels[\"forgery\"].cast('float'))\n",
        "# Pasamos el resultado anterior a un objeto RDD (Resilient Distributed Datasets) de tuplas\n",
        "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
        "\n",
        "# Mostramos la matriz de confusión\n",
        "# Filas valores reales, columnas valores predichos.\n",
        "# Primera clase (billetes verdaderos) ha predicho 218 reales (que lo eran) y 1 que era verdadero (que era falso (falso negativo)).\n",
        "# Para los billetes que ha clasificado como falsos (segunda columna). 7 ha dicho que eran falsos, siendo positivos (falso positivo) y 178 falsos siendo falsos.\n",
        "print(metrics.confusionMatrix().toArray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE-kGqEIdk8C",
        "outputId": "970bcf2a-cab2-4226-89c3-61a357703798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ia-bd-m4-sistemas-de-big-data/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[218.   7.]\n",
            " [  1. 178.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Máquinas de Vectores de Soporte (SVM) - Lineales\n",
        "\n",
        "Para más información sobre la implementación de PySpark sobre las Máquinas de Vectores de Soporte (SVM) puede consultar la [documentación de la API](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LinearSVC.html).\n",
        "\n",
        "**Ajuste de hiperparámetros del modelo.**"
      ],
      "metadata": {
        "id": "Xn5vp2o7gSIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "lsvc = LinearSVC(labelCol=\"forgery\", featuresCol=\"standardized\",\n",
        "                 maxIter=100)\n",
        "\n",
        "# Definimos los parámetros del grid donde se buscarán los parámetros óptimos\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(lsvc.regParam, [1, 0.1, 0.01, 0.001]) \\\n",
        "    .build()\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"forgery\", rawPredictionCol=\"prediction\")\n",
        "\n",
        "# Definimos la cross-validación\n",
        "crossval = CrossValidator(estimator=lsvc,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)\n",
        "\n",
        "# Ejecutar la cross-validación y elegir el mejor conjunto de parámetros\n",
        "cvModel = crossval.fit(train_df)\n",
        "\n",
        "print(\"RegParam: \" + str(cvModel.bestModel.getRegParam()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOj8cmkugdD7",
        "outputId": "8436ed27-0901-4936-c3da-dcc338b4f055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RegParam: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del modelo.**"
      ],
      "metadata": {
        "id": "jlvDgEV9gjiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "\n",
        "lsvc = LinearSVC(labelCol=\"forgery\", featuresCol=\"standardized\",\n",
        "                 maxIter=100, regParam=0.001)\n",
        "\n",
        "lsvc_model = lsvc.fit(train_df)\n",
        "pred = lsvc_model.transform(test_df)\n",
        "\n",
        "# Mostramos las clases reales junto con las predicciones realizadas\n",
        "pred.select(\"forgery\", \"features\", \"prediction\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6JE5iSVglSK",
        "outputId": "fa4b3619-c1d4-4395-fec3-78c059adc7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+----------+\n",
            "|forgery|            features|prediction|\n",
            "+-------+--------------------+----------+\n",
            "|      1|[-6.7526,8.8172,-...|       1.0|\n",
            "|      1|[-6.3979,6.4479,1...|       1.0|\n",
            "|      1|[-6.3679,8.0102,0...|       1.0|\n",
            "|      1|[-6.2003,8.6806,0...|       1.0|\n",
            "|      1|[-6.1632,8.7096,-...|       1.0|\n",
            "|      1|[-5.8818,7.6584,0...|       1.0|\n",
            "|      1|[-5.873,9.1752,-0...|       1.0|\n",
            "|      1|[-5.4414,7.2363,0...|       1.0|\n",
            "|      1|[-5.2406,6.6258,-...|       1.0|\n",
            "|      1|[-5.0676,-5.1877,...|       1.0|\n",
            "+-------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del modelo.**"
      ],
      "metadata": {
        "id": "NP07NtqVgp6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"forgery\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(pred)\n",
        "print(\"Accuracy: {}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtb-4IgAgrrc",
        "outputId": "1fa4ebc7-f270-480d-fe4c-c4320f13548f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9826732673267327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos la matriz de confusión."
      ],
      "metadata": {
        "id": "tt7B1PpBgu2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# Selecionamos solo las prediciones y los valores reales (forgery)\n",
        "preds_and_labels = pred.select(['prediction','forgery'])\n",
        "# Hacemos un casting de entero a float para la columna forgery\n",
        "preds_and_labels = preds_and_labels.withColumn(\"forgery\", preds_and_labels[\"forgery\"].cast('float'))\n",
        "# Pasamos el resultado anterior a un objeto RDD (Resilient Distributed Datasets) de tuplas\n",
        "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
        "\n",
        "# Mostramos la matriz de confusión\n",
        "print(metrics.confusionMatrix().toArray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFZVnjwKgxFz",
        "outputId": "1e23ef06-1cb1-40f2-b2bb-c80ccd95e99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/ia-bd-m4-sistemas-de-big-data/pyspark/sql/context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[219.   6.]\n",
            " [  1. 178.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Árboles de decisión - Clasificador Random Forest\n",
        "\n",
        "Para más información sobre la implementación de PySpark sobre el clasificador Random Forest puede consultar la [documentación de la API](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.RandomForestClassifier.html).\n",
        "\n",
        "**Ajuste de hiperparámetros del modelo.**"
      ],
      "metadata": {
        "id": "2ljkKzRjhYop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"forgery\", featuresCol=\"standardized\")\n",
        "\n",
        "# Definimos los parámetros del grid donde se buscarán los parámetros óptimos\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(rf.maxDepth, [3, 6, 10]) \\\n",
        "    .addGrid(rf.numTrees, [50, 100, 150, 250]) \\\n",
        "    .build()\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"forgery\", rawPredictionCol=\"prediction\")\n",
        "\n",
        "# Definimos la cross-validación\n",
        "crossval = CrossValidator(estimator=rf,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)\n",
        "\n",
        "# Ejecutar la cross-validación y elegir el mejor conjunto de parámetros\n",
        "cvModel = crossval.fit(train_df)\n",
        "\n",
        "print(\"MaxDepth: \" + str(cvModel.bestModel.getMaxDepth()))\n",
        "print(\"NumTrees: \" + str(cvModel.bestModel.getNumTrees))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bRHiz7_heO4",
        "outputId": "e041a5e4-98bf-4717-fad6-7fbe64d1322a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MaxDepth: 10\n",
            "NumTrees: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del modelo.**"
      ],
      "metadata": {
        "id": "Fdh9xRmDh7yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar un clasificador Random Forest\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"forgery\", featuresCol=\"standardized\",\n",
        "                            maxDepth=10, numTrees=100, seed=10)\n",
        "\n",
        "rf_model = rf.fit(train_df)\n",
        "pred = rf_model.transform(test_df)\n",
        "\n",
        "# Mostramos las clases reales junto con las predicciones realizadas\n",
        "pred.select(\"forgery\", \"features\", \"prediction\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B42UhNDsh9pB",
        "outputId": "4cd80a43-de55-479e-e7f5-4c2baafd666f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+----------+\n",
            "|forgery|            features|prediction|\n",
            "+-------+--------------------+----------+\n",
            "|      1|[-6.7526,8.8172,-...|       1.0|\n",
            "|      1|[-6.3979,6.4479,1...|       1.0|\n",
            "|      1|[-6.3679,8.0102,0...|       1.0|\n",
            "|      1|[-6.2003,8.6806,0...|       1.0|\n",
            "|      1|[-6.1632,8.7096,-...|       1.0|\n",
            "|      1|[-5.8818,7.6584,0...|       1.0|\n",
            "|      1|[-5.873,9.1752,-0...|       1.0|\n",
            "|      1|[-5.4414,7.2363,0...|       1.0|\n",
            "|      1|[-5.2406,6.6258,-...|       1.0|\n",
            "|      1|[-5.0676,-5.1877,...|       1.0|\n",
            "+-------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del modelo.**"
      ],
      "metadata": {
        "id": "KU0_p8ODiJgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"forgery\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(pred)\n",
        "print(\"Accuracy: {}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6O6XiaxiK_h",
        "outputId": "854270b6-e217-4101-a8cf-63f7c9ffe357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.995049504950495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos ahora la matriz de confusión. Vemos como obtenemos muy buenos resultados con este modelo (para este dataset concreto). **En general, la técnica Random Forest (así como otras derivadas de esta, como el gradient boosting) es una de las mejores técnicas de clasificación.**"
      ],
      "metadata": {
        "id": "KkVgSOjJiNgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# Selecionamos solo las prediciones y los valores reales (forgery)\n",
        "preds_and_labels = pred.select(['prediction','forgery'])\n",
        "# Hacemos un casting de entero a float para la columna forgery\n",
        "preds_and_labels = preds_and_labels.withColumn(\"forgery\", preds_and_labels[\"forgery\"].cast('float'))\n",
        "# Pasamos el resultado anterior a un objeto RDD (Resilient Distributed Datasets) de tuplas\n",
        "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
        "\n",
        "# Mostramos la matriz de confusión\n",
        "print(metrics.confusionMatrix().toArray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW11FR0BiSq4",
        "outputId": "f8291ef8-f865-4fd3-fbcd-ab19459b3b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[225.   0.]\n",
            " [  2. 177.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Árboles de Decisión - Gradient-boosted tree classifier\n",
        "\n",
        "Para más información sobre la implementación de PySpark sobre el algoritmo gradient-boosted tree classifier puede consultar la [documentación de la API](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.GBTClassifier.html).\n",
        "\n",
        "Más avanzado que el anterior. Puede usarse con datasets de terabytes. Existen implementaciones que no usan spark. Muy usado (y premiado) en torneos de ML.\n",
        "\n",
        "**Ajuste de hiperparámetros del modelo.**"
      ],
      "metadata": {
        "id": "_x-HLrKvjxW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "gbt = GBTClassifier(labelCol=\"forgery\", featuresCol=\"standardized\")\n",
        "\n",
        "# Definimos los parámetros del grid donde se buscarán los parámetros óptimos\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(gbt.maxDepth, [3, 6, 10]) \\\n",
        "    .build()\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"forgery\", rawPredictionCol=\"prediction\")\n",
        "\n",
        "# Definimos la cross-validación\n",
        "crossval = CrossValidator(estimator=gbt,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)\n",
        "\n",
        "# Ejecutar la cross-validación y elegir el mejor conjunto de parámetros\n",
        "cvModel = crossval.fit(train_df)\n",
        "\n",
        "print(\"MaxDepth: \" + str(cvModel.bestModel.getMaxDepth()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6ivAPYtj3aK",
        "outputId": "c509ebcc-27dc-4a3f-b466-a9dc1b9398d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MaxDepth: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento del modelo.**"
      ],
      "metadata": {
        "id": "J29LmSbpkUWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar un clasificador Random Forest\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "gbt = GBTClassifier(labelCol=\"forgery\", featuresCol=\"standardized\",\n",
        "                            maxDepth=10, seed=10)\n",
        "\n",
        "gbt_model = gbt.fit(train_df)\n",
        "pred = gbt_model.transform(test_df)\n",
        "\n",
        "# Mostramos las clases reales junto con las predicciones realizadas\n",
        "pred.select(\"forgery\", \"features\", \"prediction\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrMTEZ-skVxi",
        "outputId": "f23e6d3b-aa9e-4c48-c4ac-a3c8949c32cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+----------+\n",
            "|forgery|            features|prediction|\n",
            "+-------+--------------------+----------+\n",
            "|      1|[-6.7526,8.8172,-...|       1.0|\n",
            "|      1|[-6.3979,6.4479,1...|       1.0|\n",
            "|      1|[-6.3679,8.0102,0...|       1.0|\n",
            "|      1|[-6.2003,8.6806,0...|       1.0|\n",
            "|      1|[-6.1632,8.7096,-...|       1.0|\n",
            "|      1|[-5.8818,7.6584,0...|       1.0|\n",
            "|      1|[-5.873,9.1752,-0...|       1.0|\n",
            "|      1|[-5.4414,7.2363,0...|       1.0|\n",
            "|      1|[-5.2406,6.6258,-...|       1.0|\n",
            "|      1|[-5.0676,-5.1877,...|       1.0|\n",
            "+-------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del modelo.**"
      ],
      "metadata": {
        "id": "2vN5SeQskY6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"forgery\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(pred)\n",
        "print(\"Accuracy: {}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8GGOICykb2B",
        "outputId": "f1506476-c728-4c8f-8904-7db7d7549601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9900990099009901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos ahora la matriz de confusión."
      ],
      "metadata": {
        "id": "vL6eM2Bnkdjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# Selecionamos solo las prediciones y los valores reales (forgery)\n",
        "preds_and_labels = pred.select(['prediction','forgery'])\n",
        "# Hacemos un casting de entero a float para la columna forgery\n",
        "preds_and_labels = preds_and_labels.withColumn(\"forgery\", preds_and_labels[\"forgery\"].cast('float'))\n",
        "# Pasamos el resultado anterior a un objeto RDD (Resilient Distributed Datasets) de tuplas\n",
        "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
        "\n",
        "# Mostramos la matriz de confusión\n",
        "print(metrics.confusionMatrix().toArray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQlJ8jkXkexa",
        "outputId": "59236dfc-e639-42a8-df70-599cac926a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[224.   1.]\n",
            " [  3. 176.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes neuronales\n",
        "\n",
        "Para más información sobre la implementación de PySpark de las redes neuronales a través del **Multilayer Perceptron** puede consultar la [documentación de la API](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.MultilayerPerceptronClassifier.html).\n",
        "\n",
        "Si se quisiera usar otro tipo de red neuronal más compleja habría que salir de Spark y buscar paquetes específicos. El uno que se va  aajustar es el número de capas y el número de neuronas por capa. Tener en cuenta que las redes con sólo una capa oculta se consideran clasificadores universales ya que serían capacesde aproximar cualquier función.\n",
        "\n",
        "En este caso no se ha realizado ajuste de hiperparámetros porque es mucho más complejo y se escapa a los contenidos del curso. Solo se ha ajustado a ojo el número de capas y las neuronas por capa. En muchas ocasiones se prefiere usar algoritmos más fáciles de ajustar que las redes neuronales.\n",
        "\n",
        "**Entrenamiento del modelo.**"
      ],
      "metadata": {
        "id": "a3C7aBPVlJsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar un Multilayer Perceptron (un tipo de red neuronal feedforward)\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "\n",
        "# Especificamos las capas de neuronas de la red neuronal\n",
        "# Capa de entrada de tamaño 4 (las features), dos capas ocultas de tamaño\n",
        "# 10, y finalmente una capa de salida de 2 (las clases)\n",
        "layers = [4, 10, 10, 2]\n",
        "\n",
        "mlp = MultilayerPerceptronClassifier(labelCol=\"forgery\", featuresCol=\"standardized\",\n",
        "                                     maxIter=100, layers=layers, seed=10)\n",
        "\n",
        "mlp_model = mlp.fit(train_df)\n",
        "pred = mlp_model.transform(test_df)\n",
        "\n",
        "# Mostramos las clases reales junto con las predicciones realizadas\n",
        "pred.select(\"forgery\", \"features\", \"prediction\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-CX2BawlNzh",
        "outputId": "5d4c22f4-f786-4ead-862e-f19ffa242d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+----------+\n",
            "|forgery|            features|prediction|\n",
            "+-------+--------------------+----------+\n",
            "|      1|[-6.7526,8.8172,-...|       1.0|\n",
            "|      1|[-6.3979,6.4479,1...|       1.0|\n",
            "|      1|[-6.3679,8.0102,0...|       1.0|\n",
            "|      1|[-6.2003,8.6806,0...|       1.0|\n",
            "|      1|[-6.1632,8.7096,-...|       1.0|\n",
            "|      1|[-5.8818,7.6584,0...|       1.0|\n",
            "|      1|[-5.873,9.1752,-0...|       1.0|\n",
            "|      1|[-5.4414,7.2363,0...|       1.0|\n",
            "|      1|[-5.2406,6.6258,-...|       1.0|\n",
            "|      1|[-5.0676,-5.1877,...|       1.0|\n",
            "+-------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluación del modelo.**"
      ],
      "metadata": {
        "id": "R1STn1LklTgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"forgery\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(pred)\n",
        "print(\"Accuracy: {}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F1iejOzlU7Z",
        "outputId": "840d06cb-ef66-43a6-d700-c88ad58f6743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos ahora la matriz de confusión."
      ],
      "metadata": {
        "id": "rhKyvTjclXOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# Selecionamos solo las prediciones y los valores reales (forgery)\n",
        "preds_and_labels = pred.select(['prediction','forgery'])\n",
        "# Hacemos un casting de entero a float para la columna forgery\n",
        "preds_and_labels = preds_and_labels.withColumn(\"forgery\", preds_and_labels[\"forgery\"].cast('float'))\n",
        "# Pasamos el resultado anterior a un objeto RDD (Resilient Distributed Datasets) de tuplas\n",
        "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
        "\n",
        "# Mostramos la matriz de confusión\n",
        "print(metrics.confusionMatrix().toArray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vge0xn3tlZkB",
        "outputId": "1911dc8b-60d7-42b7-a190-2f193738bb76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[225.   0.]\n",
            " [  0. 179.]]\n"
          ]
        }
      ]
    }
  ]
}